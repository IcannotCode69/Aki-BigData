{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n",
        "#!pip install --upgrade scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDIzpZA35nWP",
        "outputId": "f6415980-06a8-41d5-8b58-f187b54ca60e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMRnZbmIksIz",
        "outputId": "6b269e90-b77d-4aab-e570-009914f383f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/MyDrive/Sentiment (2).csv'"
      ],
      "metadata": {
        "id": "w0_DaYZWk2mp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSxNR9zvjnVb",
        "outputId": "ed0a5a4c-7b17-4755-a959-7213c89a1e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 20s - loss: 0.8183 - accuracy: 0.6524 - 20s/epoch - 68ms/step\n",
            "144/144 - 1s - loss: 0.7573 - accuracy: 0.6785 - 1s/epoch - 8ms/step\n",
            "0.7572862505912781\n",
            "0.6784622073173523\n",
            "['loss', 'accuracy']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import re\n",
        "from keras.layers import LSTM, Embedding, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.read_csv(path_to_csv)\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "#data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "def createmodel():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1]))\n",
        "    model.add(LSTM(units=lstm_out))  # Ensure to remove any non-default configurations\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "#print(model.summary())\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "batch_size = 32\n",
        "model = createmodel()\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2)\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('sentimentalAnalysis')\n",
        "from keras.models import load_model\n",
        "model = load_model('sentimentalAnalysis')"
      ],
      "metadata": {
        "id": "q0wtb9is-HIF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "import numpy as np\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and thats a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence)\n",
        "sentence = pad_sequences (sentence, maxlen=28, dtype='int32', value=0)\n",
        "#sentiment = model.predict_classes(sentence,batch_size=1,verbose = 2) [0]\n",
        "#sentiment = (model.predict(sentence) > 0.5).astype(\"int32\")\n",
        "#sentiment = model.argmax(model.predict(sentence), axis=-1)\n",
        "predict_x=model.predict(X_test)\n",
        "sentiment=np.argmax(predict_x,axis=1)\n",
        "print(sentiment)\n",
        "if sentiment.any() == 0:\n",
        "  print(\"Neural\")\n",
        "elif sentiment.any() < 0:\n",
        "  print(\"Negative\")\n",
        "elif sentiment.any() > 0:\n",
        "  print(\"Positive\")\n",
        "else:\n",
        "  print(\"Cannot be determined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24iF-Dy-BG3r",
        "outputId": "cc9bf355-6cf1-425b-d0f3-9160e7df302f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144/144 [==============================] - 1s 3ms/step\n",
            "[0 2 2 ... 0 0 0]\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(model=createmodel,verbose=2)\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [1, 2]\n",
        "param_grid = {'batch_size':batch_size, 'epochs':epochs}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "id": "n52XQ5J6oYds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76d83a1-e917-4710-d8f3-699728f9568a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 13s - loss: 0.8189 - accuracy: 0.6560 - 13s/epoch - 18ms/step\n",
            "186/186 - 1s - 702ms/epoch - 4ms/step\n",
            "744/744 - 12s - loss: 0.8139 - accuracy: 0.6591 - 12s/epoch - 16ms/step\n",
            "186/186 - 1s - 698ms/epoch - 4ms/step\n",
            "744/744 - 15s - loss: 0.8160 - accuracy: 0.6496 - 15s/epoch - 20ms/step\n",
            "186/186 - 1s - 746ms/epoch - 4ms/step\n",
            "744/744 - 15s - loss: 0.8228 - accuracy: 0.6455 - 15s/epoch - 20ms/step\n",
            "186/186 - 1s - 741ms/epoch - 4ms/step\n",
            "744/744 - 13s - loss: 0.8175 - accuracy: 0.6507 - 13s/epoch - 17ms/step\n",
            "186/186 - 1s - 736ms/epoch - 4ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 12s - loss: 0.8178 - accuracy: 0.6552 - 12s/epoch - 16ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 4s - loss: 0.6754 - accuracy: 0.7151 - 4s/epoch - 5ms/step\n",
            "186/186 - 1s - 721ms/epoch - 4ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 14s - loss: 0.8163 - accuracy: 0.6531 - 14s/epoch - 19ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 4s - loss: 0.6741 - accuracy: 0.7164 - 4s/epoch - 6ms/step\n",
            "186/186 - 1s - 696ms/epoch - 4ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 14s - loss: 0.8148 - accuracy: 0.6488 - 14s/epoch - 19ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 5s - loss: 0.6687 - accuracy: 0.7195 - 5s/epoch - 6ms/step\n",
            "186/186 - 1s - 738ms/epoch - 4ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 14s - loss: 0.8189 - accuracy: 0.6494 - 14s/epoch - 19ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 5s - loss: 0.6696 - accuracy: 0.7186 - 5s/epoch - 7ms/step\n",
            "186/186 - 1s - 754ms/epoch - 4ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 13s - loss: 0.8105 - accuracy: 0.6561 - 13s/epoch - 17ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 5s - loss: 0.6632 - accuracy: 0.7215 - 5s/epoch - 6ms/step\n",
            "186/186 - 1s - 736ms/epoch - 4ms/step\n",
            "372/372 - 11s - loss: 0.8203 - accuracy: 0.6478 - 11s/epoch - 30ms/step\n",
            "93/93 - 1s - 522ms/epoch - 6ms/step\n",
            "372/372 - 13s - loss: 0.8182 - accuracy: 0.6525 - 13s/epoch - 34ms/step\n",
            "93/93 - 1s - 532ms/epoch - 6ms/step\n",
            "372/372 - 12s - loss: 0.8228 - accuracy: 0.6482 - 12s/epoch - 33ms/step\n",
            "93/93 - 1s - 513ms/epoch - 6ms/step\n",
            "372/372 - 12s - loss: 0.8186 - accuracy: 0.6452 - 12s/epoch - 32ms/step\n",
            "93/93 - 1s - 538ms/epoch - 6ms/step\n",
            "372/372 - 12s - loss: 0.8229 - accuracy: 0.6516 - 12s/epoch - 32ms/step\n",
            "93/93 - 1s - 680ms/epoch - 7ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 12s - loss: 0.8238 - accuracy: 0.6464 - 12s/epoch - 31ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 3s - loss: 0.6747 - accuracy: 0.7117 - 3s/epoch - 7ms/step\n",
            "93/93 - 1s - 527ms/epoch - 6ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 13s - loss: 0.8133 - accuracy: 0.6536 - 13s/epoch - 34ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 3s - loss: 0.6745 - accuracy: 0.7160 - 3s/epoch - 8ms/step\n",
            "93/93 - 1s - 518ms/epoch - 6ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 11s - loss: 0.8238 - accuracy: 0.6450 - 11s/epoch - 30ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 3s - loss: 0.6701 - accuracy: 0.7176 - 3s/epoch - 7ms/step\n",
            "93/93 - 1s - 547ms/epoch - 6ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 11s - loss: 0.8251 - accuracy: 0.6463 - 11s/epoch - 31ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 2s - loss: 0.6814 - accuracy: 0.7098 - 2s/epoch - 6ms/step\n",
            "93/93 - 1s - 540ms/epoch - 6ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 13s - loss: 0.8201 - accuracy: 0.6507 - 13s/epoch - 36ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 2s - loss: 0.6648 - accuracy: 0.7204 - 2s/epoch - 6ms/step\n",
            "93/93 - 1s - 775ms/epoch - 8ms/step\n",
            "186/186 - 11s - loss: 0.8340 - accuracy: 0.6473 - 11s/epoch - 59ms/step\n",
            "47/47 - 1s - 918ms/epoch - 20ms/step\n",
            "186/186 - 9s - loss: 0.8407 - accuracy: 0.6425 - 9s/epoch - 50ms/step\n",
            "47/47 - 1s - 656ms/epoch - 14ms/step\n",
            "186/186 - 8s - loss: 0.8415 - accuracy: 0.6435 - 8s/epoch - 44ms/step\n",
            "47/47 - 0s - 446ms/epoch - 9ms/step\n",
            "186/186 - 12s - loss: 0.8317 - accuracy: 0.6452 - 12s/epoch - 65ms/step\n",
            "47/47 - 0s - 470ms/epoch - 10ms/step\n",
            "186/186 - 10s - loss: 0.8301 - accuracy: 0.6443 - 10s/epoch - 54ms/step\n",
            "47/47 - 0s - 469ms/epoch - 10ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 11s - loss: 0.8403 - accuracy: 0.6418 - 11s/epoch - 61ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 2s - loss: 0.6853 - accuracy: 0.7104 - 2s/epoch - 11ms/step\n",
            "47/47 - 0s - 448ms/epoch - 10ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 10s - loss: 0.8335 - accuracy: 0.6442 - 10s/epoch - 55ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 3s - loss: 0.6778 - accuracy: 0.7111 - 3s/epoch - 14ms/step\n",
            "47/47 - 0s - 420ms/epoch - 9ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 10s - loss: 0.8303 - accuracy: 0.6388 - 10s/epoch - 52ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 3s - loss: 0.6767 - accuracy: 0.7140 - 3s/epoch - 17ms/step\n",
            "47/47 - 1s - 691ms/epoch - 15ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 9s - loss: 0.8370 - accuracy: 0.6409 - 9s/epoch - 49ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 3s - loss: 0.6745 - accuracy: 0.7122 - 3s/epoch - 15ms/step\n",
            "47/47 - 1s - 661ms/epoch - 14ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 10s - loss: 0.8243 - accuracy: 0.6463 - 10s/epoch - 55ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 2s - loss: 0.6692 - accuracy: 0.7176 - 2s/epoch - 12ms/step\n",
            "47/47 - 1s - 617ms/epoch - 13ms/step\n",
            "Epoch 1/2\n",
            "930/930 - 14s - loss: 0.8054 - accuracy: 0.6573 - 14s/epoch - 15ms/step\n",
            "Epoch 2/2\n",
            "930/930 - 5s - loss: 0.6687 - accuracy: 0.7183 - 5s/epoch - 5ms/step\n",
            "Best: 0.684279 using {'batch_size': 10, 'epochs': 2}\n"
          ]
        }
      ]
    }
  ]
}